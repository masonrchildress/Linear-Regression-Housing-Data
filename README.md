### Exploration and Modeling of the Ames, Iowa Housing Dataset
   The Housing dataset from Ames, Iowa presents opportunity for a comprehensive analysis on the sale price of homes based on a wide variety of features. Using a set of 80 various features, we are attempting to establish an explanatory and predictive model that will allow buyers and sellers to get an approximate estimate on a house's worth. In this file I will explain how and why I derived the data model I did and why I expect it to be valuable.

### Cleaning and Feature Engineering
   Little cleaning on the data needed be done, as nearly all of the null values in the csv file stemmed from Pandas' tendency to convert the string 'NA' to a null when reading. My feature engineering process began with converting all nominal features into dummy features so that they would map well onto a machine learning model and so finding correlations with the discrete features could be done. My next and final step was a polynomial tranformation. This step creates new features by multiplying each feature by every other feature. The conceptual understanding to this method is that it allows you to see the impact that feature 1 AND feature 2 had on Sale Price, as opposed to the two being independent.
   
### Modeling
   Seeing as the target variable is continuous, a linear regression model seemed a suiting start in the process. Also I ran tests with the ridge and lasso models, as well as using data that hadn't been run through polynomial transformation. After these tests I've decided the best model is the lasso model using the data that hadn't used the polynomial transformation. Though it did not have the highest r_squared score (.930) on the training data, it was very close to the r_squared score (.926) on the test data. And, more importantly, it had the highest r_squared for the test data and the highest cross validation score (.841). From these scores, we can tell a few things about the model. Firstly, the close pairing of the train/test R_squared scores as well as the robust .841 cross validation score show the model is not overtrained and should fairly fit other housing data in this area. And secondly, the .926 R_squared value on the testing data shows that the model explains 92.6 % of the variance in the data that the baseline model does not.
   
### Interesting Finds
   As an interesting aside, other than general living space, I found another great addition to one's home that has a great return on investment, a fireplace. Based on my model, adding one fireplace to one's home on average increases the home's value by 2.7K. However, based on the mean Sale Price per number of fireplaces, we can see that the first jump from 0 to 1 fireplace accounts for nearly 2/3 of the range in Price. Thus, I find it safe to assume that the addition of that first fireplace will add more than 2.7K in worth to your home. Seeing as the average price for a fireplace clocks in at 2.1K, you have sufficient reason to expect you will get your money back on your cozy new fireplace.